{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016dae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from cuml import RandomForestClassifier, LogisticRegression, SVC, LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from cuml.manifold import UMAP\n",
    "from skorch import NeuralNetClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import skew, kurtosis\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)  #Shows all columns\n",
    "pd.set_option('display.max_rows', None)     #Shows all rows\n",
    "pd.set_option('display.max_colwidth', None) #Shows full content of each column\n",
    "\n",
    "#Load the dataset\n",
    "file_path = r'dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "#Display basic information about the dataset\n",
    "print(\"Basic Dataset Information:\")\n",
    "print(df.info())\n",
    "\n",
    "#Display summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4f7cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's view all the variables names and data types\n",
    "print(\"Column Name and Data Type:\")\n",
    "for column in df.columns:\n",
    "    print(f\"{column}: {df[column].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f922ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create lists of my numerical and categorical features.  Created list of IDs for use in excluding them from analysis\n",
    "numerical_features = [\n",
    "    'age', 'bmi', 'height', 'weight',\n",
    "    'pre_icu_los_days',\n",
    "    'apache_2_diagnosis', 'apache_3j_diagnosis',\n",
    "    'apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob',\n",
    "    'arf_apache',\n",
    "    'gcs_eyes_apache', 'gcs_motor_apache', 'gcs_verbal_apache', 'gcs_unable_apache',\n",
    "    'heart_rate_apache', 'map_apache', 'resprate_apache', 'temp_apache',\n",
    "    'd1_diasbp_max', 'd1_diasbp_min', 'd1_diasbp_noninvasive_max', 'd1_diasbp_noninvasive_min',\n",
    "    'd1_heartrate_max', 'd1_heartrate_min',\n",
    "    'd1_mbp_max', 'd1_mbp_min', 'd1_mbp_noninvasive_max', 'd1_mbp_noninvasive_min',\n",
    "    'd1_resprate_max', 'd1_resprate_min',\n",
    "    'd1_spo2_max', 'd1_spo2_min',\n",
    "    'd1_sysbp_max', 'd1_sysbp_min', 'd1_sysbp_noninvasive_max', 'd1_sysbp_noninvasive_min',\n",
    "    'd1_temp_max', 'd1_temp_min',\n",
    "    'h1_diasbp_max', 'h1_diasbp_min', 'h1_diasbp_noninvasive_max', 'h1_diasbp_noninvasive_min',\n",
    "    'h1_heartrate_max', 'h1_heartrate_min',\n",
    "    'h1_mbp_max', 'h1_mbp_min', 'h1_mbp_noninvasive_max', 'h1_mbp_noninvasive_min',\n",
    "    'h1_resprate_max', 'h1_resprate_min',\n",
    "    'h1_spo2_max', 'h1_spo2_min',\n",
    "    'h1_sysbp_max', 'h1_sysbp_min', 'h1_sysbp_noninvasive_max', 'h1_sysbp_noninvasive_min',\n",
    "    'd1_glucose_max', 'd1_glucose_min',\n",
    "    'd1_potassium_max', 'd1_potassium_min'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'ethnicity', 'gender', 'icu_admit_source', 'icu_stay_type', 'icu_type',\n",
    "    'elective_surgery', 'apache_post_operative',\n",
    "    'intubated_apache', 'ventilated_apache',\n",
    "    'apache_3j_bodysystem', 'apache_2_bodysystem',\n",
    "    'aids', 'cirrhosis', 'diabetes_mellitus', 'hepatic_failure', 'immunosuppression',\n",
    "    'leukemia', 'lymphoma', 'solid_tumor_with_metastasis'\n",
    "]\n",
    "\n",
    "identifier_columns = [\n",
    "    'encounter_id', 'patient_id', 'hospital_id', 'icu_id'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the distributions of each numerical feature\n",
    "print(\"\\nVisualizing Distributions of Numerical Features:\")\n",
    "for column in numerical_features:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.histplot(df[column], kde=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.show()\n",
    "\n",
    "#Visualize the distribution of each categorical feature\n",
    "print(\"\\nVisualizing Distributions of Categorical Features:\")\n",
    "for column in categorical_features:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.countplot(x=column, data=df)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "#Show distribution of the target variable as well\n",
    "column = \"hospital_death\"\n",
    "plt.figure(figsize=(12, 6))  \n",
    "sns.countplot(x=column, data=df)\n",
    "plt.title(f'Distribution of {column}')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()  #Adjust layout to make room for title and labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate skewness and kurtosis for each column in the DataFrame to assess normality of each distribution\n",
    "for column in numerical_features:\n",
    "    skewness = skew(df[column].dropna())  #dropna to ignore missing values\n",
    "    kurt = kurtosis(df[column].dropna())\n",
    "    print(f\"Skewness of {column}: {skewness:.2f}\")\n",
    "    print(f\"Kurtosis of {column}: {kurt:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e206faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Highlight class imbalance\n",
    "df.groupby(['hospital_death']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11110e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling missing values\n",
    "print(\"\\nHandling Missing Values:\")\n",
    "missing_data = df.isnull().sum()\n",
    "print(\"Missing data in each column:\\n\", missing_data)\n",
    "\n",
    "#Calculate the percentage of missing data in each column\n",
    "missing_data = df.isnull().sum().sort_values(ascending=False)\n",
    "missing_percentage = (missing_data / len(df)) * 100\n",
    "\n",
    "#Filter out columns that have no missing data to clean up visualization\n",
    "missing_percentage = missing_percentage[missing_percentage > 0]\n",
    "\n",
    "#Print the percentage of missing data\n",
    "print(\"Percentage of missing data per column:\\n\")\n",
    "print(missing_percentage)\n",
    "\n",
    "#Visualizing the missing data percentages\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(x=missing_percentage.index, y=missing_percentage)\n",
    "plt.ylabel('Percentage of Missing Data')\n",
    "plt.xlabel('Columns')\n",
    "plt.title('Percentage of Missing Data by Feature')\n",
    "plt.xticks(rotation=90) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145eb557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for MCAR across all variable pairs\n",
    "def test_mcar(df):\n",
    "    \"\"\"Test for MCAR by checking if patterns of missingness are correlated across pairs of variables.\"\"\"\n",
    "    missing_indicators = df.isnull().astype(int)\n",
    "    cols = df.columns\n",
    "    mcar_vars = []\n",
    "\n",
    "    for col in cols:\n",
    "        p_values = []\n",
    "        for other_col in cols:\n",
    "            if col != other_col:\n",
    "                contingency_table = pd.crosstab(missing_indicators[col], missing_indicators[other_col])\n",
    "                _, p, _, _ = chi2_contingency(contingency_table)\n",
    "                p_values.append(p)\n",
    "        \n",
    "        #If all p-values are high, we assume MCAR for this variable\n",
    "        if all(p > 0.05 for p in p_values):\n",
    "            mcar_vars.append(col)\n",
    "\n",
    "    return mcar_vars\n",
    "\n",
    "def analyze_missingness(df):\n",
    "    \"\"\"Identify and classify the type of missing data in each variable.\"\"\"\n",
    "    #First, determine MCAR variables\n",
    "    mcar_vars = test_mcar(df)\n",
    "    mar_mnar_vars = [col for col in df.columns if col not in mcar_vars and df[col].isnull().any()]\n",
    "\n",
    "    #Assume remaining variables could be MAR or MNAR - usually requires deeper analysis or domain knowledge\n",
    "    mar_vars, mnar_vars = mar_mnar_vars, []\n",
    "\n",
    "    # Output results\n",
    "    print(\"Variables likely MCAR:\", mcar_vars)\n",
    "    print(\"Variables potentially MAR or MNAR:\", mar_vars)\n",
    "    \n",
    "analyze_missingness(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a clean dataset\n",
    "#Let's proceed with dropping the Unnamed: 83 column\n",
    "df = df.drop(columns=['Unnamed: 83'])\n",
    "df_original = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's perform imputation utilizing Medeian and Most Frequent for numerical and categorical features respectively\n",
    "numerical_imputer = SimpleImputer(strategy='median')\n",
    "df[numerical_features] = numerical_imputer.fit_transform(df[numerical_features])\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_features] = categorical_imputer.fit_transform(df[categorical_features])\n",
    "df_imputed = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Let's now show that imputation didn't modify the data distribution in a critical manner\n",
    "#Create a large figure to hold subplots\n",
    "plt.figure(figsize=(15, 85))\n",
    "\n",
    "#Create separate plots for each feature\n",
    "for column in numerical_features:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(df_original[column].dropna(), kde=True, color='blue', label='Before')\n",
    "    sns.histplot(df_imputed[column], kde=True, color='red', alpha=0.6, label='After')\n",
    "    plt.title(f'Numerical - {column}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "for column in categorical_features:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.countplot(y=column, data=df_original, color='blue', label='Before', order=df_original[column].value_counts().index)\n",
    "    sns.countplot(y=column, data=df_imputed, color='red', alpha=0.6, label='After', order=df_imputed[column].value_counts().index)\n",
    "    plt.title(f'Categorical - {column}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0672b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for numerical features only\n",
    "numerical_df = df_imputed.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numerical_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a99c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate correlation matrix for numerical features only\n",
    "numerical_df = df_imputed.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numerical_df.corr()\n",
    "# Set the default display size for heatmaps\n",
    "sns.set(rc={'figure.figsize':(20,20)})\n",
    "\n",
    "#Generate the full correlation matrix heatmap\n",
    "plt.figure(figsize=(20, 20))\n",
    "print(correlation_matrix.shape)\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title('Full Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbca64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying variables with high collinearity\n",
    "print(\"\\nIdentifying Highly Correlated Variables:\")\n",
    "threshold = 0.8  # You can adjust this threshold\n",
    "highly_correlated_pairs = []\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > threshold and (correlation_matrix.columns[j], correlation_matrix.columns[i]) not in highly_correlated_pairs:\n",
    "            highly_correlated_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j]))\n",
    "\n",
    "if not highly_correlated_pairs:\n",
    "    print(\"No highly correlated pairs found.\")\n",
    "else:\n",
    "    for pair in highly_correlated_pairs:\n",
    "        print(f\"{pair[0]} and {pair[1]} have a correlation coefficient higher than {threshold}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a1c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of variables to drop due to high correlation\n",
    "variables_to_drop = [\n",
    "    'weight', 'gcs_eyes_apache', 'd1_diasbp_noninvasive_max', 'd1_diasbp_noninvasive_min',\n",
    "    'heart_rate_apache', 'd1_diasbp_max', 'd1_mbp_min', 'd1_diasbp_min',\n",
    "    'd1_mbp_max', 'd1_sysbp_noninvasive_max', 'd1_sysbp_noninvasive_min', 'h1_diasbp_noninvasive_max',\n",
    "    'h1_diasbp_noninvasive_min', 'h1_heartrate_max', 'h1_diasbp_max', 'h1_mbp_min',\n",
    "    'h1_diasbp_min', 'h1_mbp_max', 'h1_sysbp_noninvasive_max', 'h1_mbp_noninvasive_min',\n",
    "    'h1_sysbp_noninvasive_min', 'apache_4a_hospital_death_prob'\n",
    "]\n",
    "\n",
    "#Dropping highly correlated variables\n",
    "df_imputed.drop(columns=variables_to_drop, inplace=True)\n",
    "\n",
    "#Ensure that the features to standardize are still in the dataframe after dropping correlated ones\n",
    "numerical_features = [feature for feature in numerical_features if feature in df_imputed.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e41c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new copy of imputed data frame for manipulation to save from having to re-run imputation again\n",
    "df_cleaned = df_imputed.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b62d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_zscore(df, features, threshold=2.5):\n",
    "    z_scores = np.abs(stats.zscore(df[features]))\n",
    "    mask = (z_scores < threshold).all(axis=1)\n",
    "    return df[mask], df[~mask]\n",
    "\n",
    "#Adjust the threshold and detect outliers\n",
    "#Value threshold of 10 used here as lower values resulted in large chunks (over 50% or more of the dataset being throw out)\n",
    "outlier_free_df, outliers_df = find_outliers_zscore(df_cleaned, numerical_features, threshold=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9415477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of observations remaining\n",
    "len(outlier_free_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b958d",
   "metadata": {},
   "source": [
    "# EXPERIMENT 1 - All Features + No Dim Reduction + Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e2cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###NO dimensionality reduction + no handling of class imbalance\n",
    "\n",
    "df_cleaned = outlier_free_df.copy(deep=True)  # Assuming outlier_free_df is defined\n",
    "\n",
    "#Define the percentage of the data to use\n",
    "data_percentage = 1\n",
    "df_sampled = df_cleaned.sample(frac=data_percentage, random_state=42)\n",
    "\n",
    "print(f\"Number of samples used: {len(df_sampled)}\")\n",
    "\n",
    "X = df_sampled.drop('hospital_death', axis=1)\n",
    "y = df_sampled['hospital_death'].astype(np.float32)\n",
    "\n",
    "\n",
    "#Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#Preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Apply preprocessing and convert to numpy arrays for compatibility with cuML and XGBoost\n",
    "X_train_processed = preprocessor.fit_transform(X_train).astype(np.float32)\n",
    "X_test_processed = preprocessor.transform(X_test).astype(np.float32)\n",
    "\n",
    "#We need to count the number of features after transformation\n",
    "num_features = X_train_processed.shape[1]\n",
    "\n",
    "#Define the PyTorch model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, num_features, num_units=128, activation=nn.ReLU()):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.dense1 = nn.Linear(num_features, num_units)\n",
    "        self.activation = activation\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.output = nn.Linear(num_units, 1)  #Output layer for binary classification\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.activation(self.dense1(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.output(X)\n",
    "        return X.squeeze()  #Ensure the output is of shape [batch_size]\n",
    "\n",
    "#Neural network settings\n",
    "net = NeuralNetClassifier(\n",
    "    SimpleNN,\n",
    "    module__num_features=num_features, \n",
    "    criterion=nn.BCEWithLogitsLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    max_epochs=10,\n",
    "    batch_size=64,\n",
    "    device='cuda',\n",
    "    iterator_train__shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "#Dictionary to store models and their grid search parameters\n",
    "models_params = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(max_iter=2000),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10, 100]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [10, 15, 20]\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(kernel='linear', cache_size=2000),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(tree_method='hist', device='cuda'),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [3, 6, 9],\n",
    "            'learning_rate': [0.1, 0.01, 0.001]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#Dictionary to store best models and scores\n",
    "best_models = {}\n",
    "\n",
    "#Run grid search for each model\n",
    "for model_name, info in models_params.items():\n",
    "    clf = GridSearchCV(info['model'], info['params'], cv=5, scoring='accuracy', n_jobs=1)\n",
    "    clf.fit(X_train_processed, y_train)\n",
    "    best_models[model_name] = {\n",
    "        'model': clf.best_estimator_,\n",
    "        'score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    }\n",
    "    print(f\"{model_name}: Best CV score - {clf.best_score_:.2f}\")\n",
    "    print(f\"Best parameters for {model_name}: {clf.best_params_}\")\n",
    "\n",
    "#Setup and run GridSearchCV specifically for the neural network\n",
    "nn_params = {\n",
    "    'lr': [0.1, 0.01, 0.001],\n",
    "    'max_epochs': [10, 20, 30, 50, 100],\n",
    "    'batch_size': [64, 128],\n",
    "    'module__num_units': [100, 200],\n",
    "    'module__activation': [nn.ReLU(), nn.Tanh()]\n",
    "}\n",
    "gs_nn = GridSearchCV(net, nn_params, refit=True, cv=5, scoring='accuracy', verbose=0)\n",
    "gs_nn.fit(X_train_processed, y_train)\n",
    "best_models['PyTorch NN'] = {\n",
    "    'model': gs_nn.best_estimator_,\n",
    "    'score': gs_nn.best_score_,\n",
    "    'best_params': gs_nn.best_params_\n",
    "}\n",
    "print(\"PyTorch NN: Best CV score - {:.2f}\".format(gs_nn.best_score_))\n",
    "print(\"Best parameters for PyTorch NN: \", gs_nn.best_params_)\n",
    "\n",
    "#Evaluate all models on the test set\n",
    "test_scores = {}\n",
    "for model_name, info in best_models.items():\n",
    "    test_score = info['model'].score(X_test_processed, y_test)\n",
    "    test_scores[model_name] = test_score\n",
    "    print(f\"Test Score for {model_name}: {test_score:.2f}\")\n",
    "\n",
    "#Visualization of the performance of the best model for each type\n",
    "fig, ax = plt.subplots()\n",
    "model_names = list(best_models.keys())\n",
    "scores = [test_scores[m] for m in model_names]\n",
    "ax.barh(model_names, scores, color='skyblue')\n",
    "ax.set_xlabel('Accuracy on Test Set')\n",
    "ax.set_title('Model Performance Comparison on Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf668523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate all models on the test set and generate precision and recall values and \n",
    "#visualize cross validation and test score results\n",
    "test_scores = {}\n",
    "additional_metrics = {}\n",
    "for model_name, info in best_models.items():\n",
    "    model = info['model']\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    test_scores[model_name] = model.score(X_test_processed, y_test)\n",
    "    #y_prob = model.decision_function(X_test_umap)\n",
    "    #auc_score = roc_auc_score(y_test, y_prob)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    additional_metrics[model_name] = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1#,\n",
    "        #'auc': auc_score\n",
    "    }\n",
    "    print(f\"Test Score for {model_name}: {test_scores[model_name]:.9f}\")\n",
    "    print(f\"Precision for {model_name}: {precision:.9f}\")\n",
    "    print(f\"Recall for {model_name}: {recall:.9f}\")\n",
    "    print(f\"F1 Score for {model_name}: {f1:.9f}\")\n",
    "    #print(f\"AUC Score for {model_name}: {auc_score:.9f}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "model_names = list(best_models.keys())\n",
    "scores = [best_models[m]['score'] for m in model_names]\n",
    "bar_height = 0.4\n",
    "ax.barh(model_names, scores, height=bar_height, color='skyblue')\n",
    "ax.set_xlabel('Best Cross-Validation Accuracy')\n",
    "ax.set_title('Model Comparison')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "scores = [test_scores[m] for m in model_names]\n",
    "ax.barh(model_names, scores, height=bar_height, color='skyblue')\n",
    "ax.set_xlabel('Accuracy on Test Set')\n",
    "ax.set_title('Model Performance Comparison on Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf3b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Feature Importances\n",
    "feature_importances = {}\n",
    "for model_name, model_info in best_models.items():\n",
    "    model = model_info['model']\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_importances[model_name] = model.feature_importances_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        feature_importances[model_name] = np.abs(model.coef_)\n",
    "\n",
    "#Neural Network Permutation Importance\n",
    "nn_model = best_models['PyTorch NN']['model']\n",
    "perm = permutation_importance(nn_model, X_test_processed, y_test, n_repeats=5, random_state=42)\n",
    "feature_importances['PyTorch NN'] = perm.importances_mean\n",
    "\n",
    "for model_name, importances in feature_importances.items():\n",
    "    print(f\"Feature importances for {model_name}: {importances}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25acc98b",
   "metadata": {},
   "source": [
    "# EXPERIMENT 2 - UMAP + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45c9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "###UMAP + SMOTE \n",
    "df_cleaned = outlier_free_df.copy(deep=True)  \n",
    "\n",
    "#Define the percentage of the data to use\n",
    "data_percentage = 1\n",
    "df_sampled = df_cleaned.sample(frac=data_percentage, random_state=42)\n",
    "\n",
    "print(f\"Number of samples used: {len(df_sampled)}\")\n",
    "\n",
    "X = df_sampled.drop('hospital_death', axis=1)\n",
    "y = df_sampled['hospital_death'].astype(np.float32)\n",
    "\n",
    "#Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#Preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Apply preprocessing\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "#Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_processed, y_train = smote.fit_resample(X_train_processed, y_train)\n",
    "\n",
    "\n",
    "#Initialize and fit UMAP\n",
    "umap_reducer = UMAP(n_components=3, n_neighbors=15, random_state=42)\n",
    "X_train_umap = umap_reducer.fit_transform(X_train_processed.astype(np.float32))\n",
    "X_test_umap = umap_reducer.transform(X_test_processed.astype(np.float32))\n",
    "\n",
    "#Define models and parameters for GridSearchCV\n",
    "models_params = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(max_iter=2000),\n",
    "        'params': {\n",
    "            'C': [0.01, 0.1, 1, 10, 100]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200, 400],\n",
    "            'max_depth': [10, 15, 20, 50]\n",
    "        }\n",
    "    },\n",
    "    'Linear SVC': {\n",
    "        'model': LinearSVC(),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10, 100]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(tree_method='hist', device='cuda'),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200, 500],\n",
    "            'max_depth': [3, 6, 9, 15, 30],\n",
    "            'learning_rate': [0.1, 0.01, 0.001]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "#Dictionary to store best models and scores\n",
    "best_models = {}\n",
    "\n",
    "#Run grid search for each model\n",
    "for model_name, info in models_params.items():\n",
    "    start_time = time.time()\n",
    "    clf = GridSearchCV(info['model'], info['params'], cv=5, scoring='accuracy', n_jobs=1)\n",
    "    clf.fit(X_train_umap, y_train)\n",
    "    end_time = time.time()\n",
    "    best_models[model_name] = {\n",
    "        'model': clf.best_estimator_,\n",
    "        'score': clf.best_score_,\n",
    "        'best_params': clf.best_params_,\n",
    "        'training_time': end_time - start_time\n",
    "    }\n",
    "    print(f\"{model_name}: Best CV score - {clf.best_score_:.9f}\")\n",
    "    print(f\"Best parameters for {model_name}: {clf.best_params_}\")\n",
    "    print(f\"Training time for {model_name}: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "#Setup and run GridSearchCV specifically for the neural network\n",
    "nn_params = {\n",
    "    'lr': [0.1, 0.01, 0.001],\n",
    "    'max_epochs': [10, 20, 30, 50, 100],\n",
    "    'batch_size': [64, 128],\n",
    "    'module__num_units': [100, 200],\n",
    "    'module__activation': [nn.ReLU(), nn.Tanh()]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c34f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the PyTorch model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, num_features, num_units=128, activation=nn.ReLU()):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.dense1 = nn.Linear(num_features, num_units)\n",
    "        self.activation = activation\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.output = nn.Linear(num_units, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.activation(self.dense1(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.output(X)\n",
    "        return X.squeeze()\n",
    "\n",
    "#Neural network settings\n",
    "net = NeuralNetClassifier(\n",
    "    SimpleNN,\n",
    "    module__num_features=3,\n",
    "    criterion=nn.BCEWithLogitsLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    max_epochs=10,\n",
    "    batch_size=64,\n",
    "    device='cuda',\n",
    "    iterator_train__shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2432252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate over gridsearch best perfroming Neural Network.  \n",
    "start_time = time.time()\n",
    "gs_nn = GridSearchCV(net, nn_params, refit=True, cv=5, scoring='accuracy', verbose=0)\n",
    "gs_nn.fit(X_train_umap, y_train)\n",
    "end_time = time.time()\n",
    "best_models['PyTorch NN'] = {\n",
    "    'model': gs_nn.best_estimator_,\n",
    "    'score': gs_nn.best_score_,\n",
    "    'best_params': gs_nn.best_params_,\n",
    "    'training_time': end_time - start_time\n",
    "}\n",
    "print(\"PyTorch NN: Best CV score - {:.9f}\".format(gs_nn.best_score_))\n",
    "print(\"Best parameters for PyTorch NN: \", gs_nn.best_params_)\n",
    "print(f\"Training time for PyTorch NN: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b876c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate all models on the test set\n",
    "test_scores = {}\n",
    "for model_name, info in best_models.items():\n",
    "    test_score = info['model'].score(X_test_umap, y_test)\n",
    "    test_scores[model_name] = test_score\n",
    "    print(f\"Test Score for {model_name}: {test_score:.9f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13721ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "model_names = list(best_models.keys())\n",
    "scores = [best_models[m]['score'] for m in model_names]\n",
    "bar_height = 0.4\n",
    "ax.barh(model_names, scores, height=bar_height, color='skyblue')\n",
    "ax.set_xlabel('Best Cross-Validation Accuracy')\n",
    "ax.set_title('Model Comparison')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "scores = [test_scores[m] for m in model_names]\n",
    "ax.barh(model_names, scores, height=bar_height, color='skyblue')\n",
    "ax.set_xlabel('Accuracy on Test Set')\n",
    "ax.set_title('Model Performance Comparison on Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd853252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate all models on the test set and generate additional metrics of interest:  Precision and Recall\n",
    "test_scores = {}\n",
    "additional_metrics = {}\n",
    "for model_name, info in best_models.items():\n",
    "    model = info['model']\n",
    "    y_pred = model.predict(X_test_umap)\n",
    "    test_scores[model_name] = model.score(X_test_umap, y_test)\n",
    "    #y_prob = model.decision_function(X_test_umap)\n",
    "    #auc_score = roc_auc_score(y_test, y_prob)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    additional_metrics[model_name] = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1#,\n",
    "        #'auc': auc_score\n",
    "    }\n",
    "    print(f\"Test Score for {model_name}: {test_scores[model_name]:.9f}\")\n",
    "    print(f\"Precision for {model_name}: {precision:.9f}\")\n",
    "    print(f\"Recall for {model_name}: {recall:.9f}\")\n",
    "    print(f\"F1 Score for {model_name}: {f1:.9f}\")\n",
    "    #print(f\"AUC Score for {model_name}: {auc_score:.9f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd2d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Feature Importances\n",
    "feature_importances = {}\n",
    "for model_name, model_info in best_models.items():\n",
    "    model = model_info['model']\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_importances[model_name] = model.feature_importances_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        feature_importances[model_name] = np.abs(model.coef_)\n",
    "\n",
    "# Neural Network Permutation Importance\n",
    "nn_model = best_models['PyTorch NN']['model']\n",
    "perm = permutation_importance(nn_model, X_test_umap, y_test, n_repeats=5, random_state=42)\n",
    "feature_importances['PyTorch NN'] = perm.importances_mean\n",
    "\n",
    "for model_name, importances in feature_importances.items():\n",
    "    print(f\"Feature importances for {model_name}: {importances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53cc874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71865976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f66417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAPIDS 24.04",
   "language": "python",
   "name": "rapids-24.04"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
